View(x)
x = x[,c(-1,-3,-5,-7)]
View(x)
FINAL.RESULTS = x
colnames(FINAL.RESULTS) = c('Tree A','Tree B','NB A', 'NB B')
grid.table(FINAL.RESULTS)
scale(FINAL.RESULTS$`Tree A`)
# =============================================================================================================
#
#
scaleDFCol = function(dataset, colsToScale, colsNotScale) {
max = apply(dataset[,colsToScale], 2, max)
min = apply(dataset[,colsToScale], 2, min)
scaledDF = as.data.frame(cbind(dataset[,colsNotScale], scale(dataset[,colsToScale], center = min, scale = max-min)))
return(scaledDF)
}
t = scaleDFCol(FINAL.RESULTS,c(1:4), 0)
View(t)
percent(FINAL.RESULTS)
percent(FINAL.RESULTS$`Tree A`)
sum(FINAL.RESULTS$`Tree A`)
sum(FINAL.RESULTS$`NB B`)
FINAL.RESULTS$`Tree A`/sum(FINAL.RESULTS$`Tree A`)
FINAL.RESULTS/sum(FINAL.RESULTS$`Tree A`)
percent(FINAL.RESULTS/sum(FINAL.RESULTS$`Tree A`))
library(scales)
percent(FINAL.RESULTS$`Tree A`/1000)
FINAL.RESULTS/sum(FINAL.RESULTS$`Tree A`)
percent(FINAL.RESULTS$`Tree A`/1000)
percent(FINAL.RESULTS$`Tree A`)
scale(FINAL.RESULTS$`Tree A`)
for (i in 1:ncol(FINAL.RESULTS)) {
FINAL.RESULTS[,i] = percent(FINAL.RESULTS[,i]/sum(FINAL.RESULTS[,i]))
}
FINAL.RESULTS
FR.PER = data.frame()
grid.table(FINAL.RESULTS)
max(DIGIT_OG)
testingSample = function(dataSet) {
returnList = list()
trainSet = dataSet[1:ceiling(nrow(dataSet)*.7),] # 70% for train
testSet = dataSet[(ceiling(nrow(dataSet)*.7)+1):nrow(dataSet),] # 30% for test
returnList[[1]] = trainSet
returnList[[2]] = testSet
return(returnList)
}
test = testingSample(digit.df)
test_df = test[1]
test_df = test[[1]]
View(test)
# =============================================================================================================
#
testingSample = function(dataSet) {
returnList = list()
trainSet = dataSet[1:ceiling(nrow(dataSet)*.7),] # 70% for train
testSet = dataSet[(ceiling(nrow(dataSet)*.7)+1):nrow(dataSet),] # 30% for test
returnList[1] = trainSet
returnList[2] = testSet
return(returnList)
}
test = testingSample(digit.df)
# =============================================================================================================
#
testingSample = function(dataSet) {
returnList = list()
trainSet = dataSet[1:ceiling(nrow(dataSet)*.7),] # 70% for train
testSet = dataSet[(ceiling(nrow(dataSet)*.7)+1):nrow(dataSet),] # 30% for test
returnList[[1]] = trainSet
returnList[[2]] = testSet
return(returnList)
}
# plot the numbers
plotIt(digit.df[digit.df$label==0,])
plotIt(digitSet.1[digitSet.1$label==0,])
plotIt(digit.df[digit.df$label==1,])
plotIt(digit.df[digit.df$label==2,])
plotIt(digitSet.1[digitSet.1$label==2,])
plotIt(digit.df[digit.df$label==4,])
plotIt(digitSet.1[digitSet.1$label==4,])
plotIt(digit.df[digit.df$label==6,])
plotIt(digitSet.1[digitSet.1$label==6,])
plotIt(digit.df[digit.df$label==8,])
plotIt(digitSet.1[digitSet.1$label==8,])
plotIt(digit.df[digit.df$label==9,])
plotIt(digit.df[digit.df$label==5,])
plotIt(digitSet.1[digitSet.1$label==5,])
trainSet
?cp
?rpart.control
?naiveBayes
loadLibraries()
?naiveBayes
?naiveBayes
conMatrix.A = table(pred_tree.A, trainSet$label)
(matrixStats.A = confusionMatrix(conMatrix.A))
# plots
grid.table(matrixStats.A)
dev.off(dev.list()["RStudioGD"]) # clear plots
# plots
grid.table(matrixStats.A)
test.A = predict(model_naive.A, trainSet[,-1], type = "class")
loadLibraries()
test.A = predict(model_naive.A, trainSet[,-1], type = "class")
test.A = table(test.A, trainSet$label)
(test.nb.A = confusionMatrix(test.A))
test.B = predict(model_naive.B, trainSet.1[,-1], type = "class")
test.B = table(test.B, trainSet.1$label)
(test.nb.B = confusionMatrix(test.B))
(matstat.nb.B = confusionMatrix(conMat_NB.B))
(test.nb.A = confusionMatrix(test.A))
(matstat.nb.A = confusionMatrix(conMat_NB.A))
(test.nb.B = confusionMatrix(test.B))
(matstat.nb.B = confusionMatrix(conMat_NB.B))
rnorm(10)
# plots
grid.table(conMatrix.test.A)
grid.table(conMatrix.B)
# plots
grid.table(conMatrix.test.A)
# plots
grid.table(conMatrix.test.B)
# plots
grid.table(conMatrix.test.B)
#plot
grid.table(conMat_NB.A)
#plot
grid.table(conMat_NB.A)
#plot
grid.table(conMat_NB.B)
summary(model_naive.A)
model_naive.A
install.packages("naivebayes")
library(naivebayes)
?naive_bayes
test.nb = naive_bayes(trainSet.1$label ~., data = trainSet.1, laplace = 1, na.action = na.pass)
model = pred_naive_nb = predict(test.nb, testSet.1[,-1], type = "class")
#model_naive.B = naiveBayes(trainSet.1$label ~., data = trainSet.1, laplace = 1, na.action = na.pass)
test.nb = naive_bayes(trainSet.1$label ~., data = trainSet.1, laplace = 1, na.action = na.pass)
summary(test.nb)
model = predict(test.nb, testSet.1[,-1], type = "class")
test.cm = table(model, testSet.1$label)
#model_naive.B = naiveBayes(trainSet.1$label ~., data = trainSet.1, laplace = 1, na.action = na.pass)
test.nb = naive_bayes(trainSet.1$label ~., data = trainSet.1, laplace = 1, na.action = na.pass)
model = predict(test.nb, testSet.1[,-1], type = "class")
test_cm = table(model, testSet.1$label)
(test_nb = confusionMatrix(test.B))
loadLibraries()
# Diego Valdes
# IST 707
# Apr 14, 2019
# Functions
# =============================================================================================================
# load libraries
#
loadLibraries = function() {
#library(tidyr)
#library(reshape)
library(gridExtra)
library(grid)
library(ggplot2)
#library(lattice)
#library(arules)
#library(arulesViz)
#library(datasets)
library(cluster)
library(factoextra)
library(pvclust)
library(reshape2)
library(plyr)
library(scales)
library(fpc)
library(HSAUR)
library(ClustMMDD)
library(tm)
#install.packages("tm")
library(stringr)
library(wordcloud)
# ONCE: install.packages("Snowball")
## NOTE Snowball is not yet available for R v 3.5.x
## So I cannot use it  - yet...
##library("Snowball")
##set working directory
## ONCE: install.packages("slam")
library(slam)
library(quanteda)
## ONCE: install.packages("quanteda")
## Note - this includes SnowballC
library(SnowballC)
library(arules)
##ONCE: install.packages('proxy')
library(proxy)
library(cluster)
library(stringi)
library(proxy)
library(Matrix)
library(tidytext) # convert DTM to DF
library(plyr) ## for adply
library(ggplot2)
library(factoextra) # for fviz
library(mclust) # for Mclust EM clustering
library(gofastr)
library(RColorBrewer)
library(e1071)
library(openxlsx)
library(ISLR)
library(MASS)
library(randomForest)
library(caret)
library(rpart)
library(rattle)
library(rpart.plot)
library(Cairo)
}
loadLibraries()
loadLibraries()
# =============================================================================================================
# load libraries
#
loadLibraries = function() {
#library(tidyr)
#library(reshape)
library(gridExtra)
library(grid)
library(ggplot2)
#library(lattice)
#library(arules)
#library(arulesViz)
#library(datasets)
library(cluster)
library(factoextra)
library(pvclust)
library(reshape2)
library(plyr)
library(scales)
library(fpc)
library(HSAUR)
library(ClustMMDD)
library(tm)
#install.packages("tm")
library(stringr)
library(wordcloud)
# ONCE: install.packages("Snowball")
## NOTE Snowball is not yet available for R v 3.5.x
## So I cannot use it  - yet...
##library("Snowball")
##set working directory
## ONCE: install.packages("slam")
library(slam)
library(quanteda)
## ONCE: install.packages("quanteda")
## Note - this includes SnowballC
library(SnowballC)
library(arules)
##ONCE: install.packages('proxy')
library(proxy)
library(cluster)
library(stringi)
library(proxy)
library(Matrix)
library(tidytext) # convert DTM to DF
library(plyr) ## for adply
library(ggplot2)
library(factoextra) # for fviz
library(mclust) # for Mclust EM clustering
library(gofastr)
library(RColorBrewer)
library(e1071)
library(openxlsx)
library(ISLR)
library(MASS)
library(randomForest)
library(caret)
library(rpart)
library(rattle)
library(rpart.plot)
library(Cairo)
}
loadLibraries()
# =============================================================================================================
# load libraries
#
loadLibraries = function() {
#library(tidyr)
#library(reshape)
library(gridExtra)
library(grid)
library(ggplot2)
#library(lattice)
#library(arules)
#library(arulesViz)
#library(datasets)
library(cluster)
library(factoextra)
library(pvclust)
library(reshape2)
library(plyr)
library(scales)
library(fpc)
library(HSAUR)
library(ClustMMDD)
library(tm)
#install.packages("tm")
library(stringr)
library(wordcloud)
# ONCE: install.packages("Snowball")
## NOTE Snowball is not yet available for R v 3.5.x
## So I cannot use it  - yet...
##library("Snowball")
##set working directory
## ONCE: install.packages("slam")
library(slam)
library(quanteda)
## ONCE: install.packages("quanteda")
## Note - this includes SnowballC
library(SnowballC)
library(arules)
##ONCE: install.packages('proxy')
library(proxy)
library(cluster)
library(stringi)
library(proxy)
library(Matrix)
library(tidytext) # convert DTM to DF
library(plyr) ## for adply
library(ggplot2)
library(factoextra) # for fviz
library(mclust) # for Mclust EM clustering
library(gofastr)
library(RColorBrewer)
library(e1071)
library(openxlsx)
library(ISLR)
library(MASS)
library(randomForest)
library(caret)
library(rpart)
library(rattle)
library(rpart.plot)
library(Cairo)
}
#library(tidyr)
#library(reshape)
library(gridExtra)
install.packages("gridExtra")
# =============================================================================================================
# load libraries
#
loadLibraries = function() {
#library(tidyr)
#library(reshape)
library(gridExtra)
library(grid)
library(ggplot2)
#library(lattice)
#library(arules)
#library(arulesViz)
#library(datasets)
library(cluster)
library(factoextra)
library(pvclust)
library(reshape2)
library(plyr)
library(scales)
library(fpc)
library(HSAUR)
library(ClustMMDD)
library(tm)
#install.packages("tm")
library(stringr)
library(wordcloud)
# ONCE: install.packages("Snowball")
## NOTE Snowball is not yet available for R v 3.5.x
## So I cannot use it  - yet...
##library("Snowball")
##set working directory
## ONCE: install.packages("slam")
library(slam)
library(quanteda)
## ONCE: install.packages("quanteda")
## Note - this includes SnowballC
library(SnowballC)
library(arules)
##ONCE: install.packages('proxy')
library(proxy)
library(cluster)
library(stringi)
library(proxy)
library(Matrix)
library(tidytext) # convert DTM to DF
library(plyr) ## for adply
library(ggplot2)
library(factoextra) # for fviz
library(mclust) # for Mclust EM clustering
library(gofastr)
library(RColorBrewer)
library(e1071)
library(openxlsx)
library(ISLR)
library(MASS)
library(randomForest)
library(caret)
library(rpart)
library(rattle)
library(rpart.plot)
library(Cairo)
}
loadLibraries()
library(ggplot2)
install.packages("ggplot2")
library(Cairo)
install.packages("Cairo")
library(Cairo)
(test_nb = confusionMatrix(test.B))
test_cm = table(model, testSet.1$label)
library(caret)
install.packages("caret")
(test_nb = confusionMatrix(test_cm))
library(cluster)
library(stringi)
library(proxy)
library(RColorBrewer)
library(e1071)
library(openxlsx)
library(ISLR)
library(MASS)
library(randomForest)
library(caret)
# =============================================================================================================
# load libraries
#
list.of.packages <- c("ggplot2", "Rcpp")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
#library(lattice)
#library(arules)
#library(arulesViz)
#library(datasets)
library(cluster)
library(factoextra)
# =============================================================================================================
# load libraries
#
list.of.packages <- c("ggplot2", "Rcpp", "factoextra")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
list.of.packages <- c("ggplot2", "Rcpp", "factoextra", "gridExtra", "grid", "cluster", "pvclust", "reshape2", "plyr", "scales",
"fpc", "HSAUR", "ClustMMDD", "tm", "stringr", "wordcloud", "slam", "quanteda", "SnowballC", "arules", "proxy", "cluster",
"stringi", "proxy", "Matrix", "tidytext", "plyr", "mclust", "gofastr", "RColorBrewer", "e1071", "openxlsx", "ISLR",
"MASS", "randomForest", "caret", "rpart", "rattle", "rpart.plot", "Cairo")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
loadLibraries = function() {
#library(tidyr)
#library(reshape)
library(gridExtra)
library(grid)
library(ggplot2)
#library(lattice)
#library(arules)
#library(arulesViz)
#library(datasets)
library(cluster)
library(factoextra)
library(pvclust)
library(reshape2)
library(plyr)
library(scales)
library(fpc)
library(HSAUR)
library(ClustMMDD)
library(tm)
#install.packages("tm")
library(stringr)
library(wordcloud)
# ONCE: install.packages("Snowball")
## NOTE Snowball is not yet available for R v 3.5.x
## So I cannot use it  - yet...
##library("Snowball")
##set working directory
## ONCE: install.packages("slam")
library(slam)
library(quanteda)
## ONCE: install.packages("quanteda")
## Note - this includes SnowballC
library(SnowballC)
library(arules)
##ONCE: install.packages('proxy')
library(proxy)
library(cluster)
library(stringi)
library(proxy)
library(Matrix)
library(tidytext) # convert DTM to DF
library(plyr) ## for adply
library(ggplot2)
library(factoextra) # for fviz
library(mclust) # for Mclust EM clustering
library(gofastr)
library(RColorBrewer)
library(e1071)
library(openxlsx)
library(ISLR)
library(MASS)
library(randomForest)
library(caret)
library(rpart)
library(rattle)
library(rpart.plot)
library(Cairo)
}
loadLibraries()
(test_nb = confusionMatrix(test_cm))
