#
display = function(x) {
par(mar=c(0, 0, 0, 0))
#image(m, useRaster=TRUE, axes=FALSE)
image(x, axes = FALSE, col = grey(seq(0, 1, length = 256)))
}
# =============================================================================================================
#
plotIt = function(x) {
x = gridify(x[1,-1])
x = rotate(x)
return(display(x))
}
# =============================================================================================================
#
testingSample = function(dataSet) {
returnList = list()
trainSet = dataSet[1:ceiling(nrow(dataSet)*.7),] # 70% for train
testSet = dataSet[(ceiling(nrow(dataSet)*.7)+1):nrow(dataSet),] # 30% for test
returnList[[1]] = trainSet
returnList[[2]] = testSet
return(returnList)
}
# =============================================================================================================
# IMPORT AND CLEAN DATA
# =============================================================================================================
# https://www.kaggle.com/c/digit-recognizer/data
DIGIT_OG = read.csv("Kaggle-digit-train-sample-small-1400.csv")
str(DIGIT_OG)
digit.df = DIGIT_OG
digit.df$label = factor(digit.df$label)
str(digit.df$label)
# train and testing dataset
digit.df = digit.df[sample(nrow(digit.df)), ] # randomize
trainSet = digit.df[1:ceiling(nrow(digit.df)*.7),] # 70% for train
testSet = digit.df[(ceiling(nrow(digit.df)*.7)+1):nrow(digit.df),] # 30% for test
# values as 1 or 0
digitSet.1 = digit.df
for (i in 2:ncol(digitSet.1)) {
digitSet.1[,i] = ifelse(digitSet.1[,i] > 0, 1,0)
}
# compare the two plots
plotIt(digit.df)
plotIt(digitSet.1)
# compare the two plots
plotIt(digit.df)
plotIt(digitSet.1)
# train and test sets for datasets 1|0
trainSet.1 = digitSet.1[1:ceiling(nrow(digitSet.1)*.7),] # 70% for train
testSet.1 = digitSet.1[(ceiling(nrow(digitSet.1)*.7)+1):nrow(digitSet.1),] # 30% for test
# final test set
DIGIT_TEST_OG = read.csv("Kaggle-digit-test-sample1000.csv")
digit.test = DIGIT_TEST_OG
digit.test$label = factor(digit.test$label)
# train and test sets for datasets 1|0
trainset_list = testingSample(digitSet.1)
trainset.1 = trainset_list[1]
rm(trainset.1)
trainset.1 = trainset_list[[1]]
testset.1 = trainset_list[[2]]
trainSet_list = testingSample(digit.df)
trainSet = trainSet_list[[1]]
testSet = trainSet_list[[2]]
rm(list=ls()) # clear work space
loadLibraries = function() {
#library(tidyr)
#library(reshape)
library(gridExtra)
library(grid)
library(ggplot2)
#library(lattice)
#library(arules)
#library(arulesViz)
#library(datasets)
library(cluster)
library(factoextra)
library(pvclust)
library(reshape2)
library(plyr)
library(scales)
library(fpc)
library(HSAUR)
library(ClustMMDD)
library(tm)
#install.packages("tm")
library(stringr)
library(wordcloud)
# ONCE: install.packages("Snowball")
## NOTE Snowball is not yet available for R v 3.5.x
## So I cannot use it  - yet...
##library("Snowball")
##set working directory
## ONCE: install.packages("slam")
library(slam)
library(quanteda)
## ONCE: install.packages("quanteda")
## Note - this includes SnowballC
library(SnowballC)
library(arules)
##ONCE: install.packages('proxy')
library(proxy)
library(cluster)
library(stringi)
library(proxy)
library(Matrix)
library(tidytext) # convert DTM to DF
library(plyr) ## for adply
library(ggplot2)
library(factoextra) # for fviz
library(mclust) # for Mclust EM clustering
library(gofastr)
library(RColorBrewer)
library(e1071)
library(openxlsx)
library(ISLR)
library(MASS)
library(randomForest)
library(caret)
library(rpart)
library(rattle)
library(rpart.plot)
library(Cairo)
}
loadLibraries()
(originalWD = getwd()) # get original wd for saving to .r file
setwd("C:/Users/dvjr2/Google Drive/Documents/Syracuse/IST_707/HW/007_HW")
gridify = function(RowToGridify) {
test.df = data.frame()
y=28
x=1
for (i in 1:ncol(RowToGridify)) {
r1 = RowToGridify[1,c(x:y)]
colnames(r1) = c(1:28)
x=x+28
y=y+28
test.df = rbind(test.df,r1)
if(y>ncol(RowToGridify)) break
}
test.df
}
# =============================================================================================================
#
rotate = function(x) {
x = as.matrix(x)
t(apply(x, 2, rev))
}
# =============================================================================================================
#
display = function(x) {
par(mar=c(0, 0, 0, 0))
#image(m, useRaster=TRUE, axes=FALSE)
image(x, axes = FALSE, col = grey(seq(0, 1, length = 256)))
}
# =============================================================================================================
#
plotIt = function(x) {
x = gridify(x[1,-1])
x = rotate(x)
return(display(x))
}
# =============================================================================================================
#
testingSample = function(dataSet) {
returnList = list()
trainSet = dataSet[1:ceiling(nrow(dataSet)*.7),] # 70% for train
testSet = dataSet[(ceiling(nrow(dataSet)*.7)+1):nrow(dataSet),] # 30% for test
returnList[[1]] = trainSet
returnList[[2]] = testSet
return(returnList)
}
# =============================================================================================================
# IMPORT AND CLEAN DATA
# =============================================================================================================
# https://www.kaggle.com/c/digit-recognizer/data
DIGIT_OG = read.csv("Kaggle-digit-train-sample-small-1400.csv")
str(DIGIT_OG)
digit.df = DIGIT_OG
digit.df$label = factor(digit.df$label)
str(digit.df$label)
# train and testing dataset
digit.df = digit.df[sample(nrow(digit.df)), ] # randomize
trainSet_list = testingSample(digit.df)
trainSet = trainSet_list[[1]]
testSet = trainSet_list[[2]]
# values as 1 or 0
digitSet.1 = digit.df
for (i in 2:ncol(digitSet.1)) {
digitSet.1[,i] = ifelse(digitSet.1[,i] > 0, 1,0)
}
# train and test sets for datasets 1|0
trainset_list = testingSample(digitSet.1)
trainSet.1 = trainset_list[[1]]
testSet.1 = trainset_list[[2]]
# final test set
DIGIT_TEST_OG = read.csv("Kaggle-digit-test-sample1000.csv")
digit.test = DIGIT_TEST_OG
digit.test$label = factor(digit.test$label)
list.of.packages <- c("ggplot2", "Rcpp", "factoextra", "gridExtra", "grid", "cluster", "pvclust", "reshape2", "plyr", "scales",
"fpc", "HSAUR", "ClustMMDD", "tm", "stringr", "wordcloud", "slam", "quanteda", "SnowballC", "arules", "proxy", "cluster",
"stringi", "proxy", "Matrix", "tidytext", "plyr", "mclust", "gofastr", "RColorBrewer", "e1071", "openxlsx", "ISLR",
"MASS", "randomForest", "caret", "rpart", "rattle", "rpart.plot", "Cairo", "class")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
library(class)
knn.train = trainSet
str(knn.train[1:10])
train_label = trainSet$label
model.knn = knn(train = trainSet, test = testSet, cl = train_label, k = 3)
length(model.knn)
knn.matrix = table(model.knn, testSet$label)
knn.matrix.stats = confusionMatrix(knn.matrix)
(knn.matrix.stats = confusionMatrix(knn.matrix))
model.knn = knn(train = trainSet, test = testSet, cl = train_label, k = 5)
knn.matrix = table(model.knn, testSet$label)
(knn.matrix.stats = confusionMatrix(knn.matrix))
model.knn = knn(train = trainSet, test = testSet, cl = train_label, k = 7)
knn.matrix = table(model.knn, testSet$label)
(knn.matrix.stats = confusionMatrix(knn.matrix))
model.knn = knn(train = trainSet, test = testSet, cl = train_label, k = 9)
knn.matrix = table(model.knn, testSet$label)
(knn.matrix.stats = confusionMatrix(knn.matrix))
model.knn = knn(train = trainSet, test = testSet, cl = train_label, k = 5)
knn.matrix = table(model.knn, testSet$label)
(knn.matrix.stats = confusionMatrix(knn.matrix))
model.svm = svm(label ~. , data = trainSet)
model.svm = svm(label = trainSet[2] , data = trainSet)
# =============================================================================================================
# SVM
# =============================================================================================================
test = trainSet[,1:10]
model.svm = svm(label ~. , data = test)
# =============================================================================================================
# get number of na in each column
#
naInData = function(dataset) {
nas = c()
for (i in 1:length(dataset)) {
nas = cbind(nas, sum(is.na(dataset[,i])))
}
nas = data.frame(nas)
colnames(nas) = colnames(dataset)
return(nas)
}
# =============================================================================================================
# converts cols in a dataset to factor
#
toFactor = function(dataset, columns) {
for (i in 1:length(columns)) {
dataset[,columns[i]] = as.factor(dataset[,columns[i]])
}
return(dataset)
}
# =============================================================================================================
# converts cols in a dataset to numeric
#
toNumeric = function(dataset, columns) {
for (i in 1:length(columns)) {
dataset[,columns[i]] = as.numeric(dataset[,columns[i]])
}
return(dataset)
}
# =============================================================================================================
# SVM
# =============================================================================================================
test = toFactor(trainSet, c(2:785))
model.svm = svm(label ~. , data = test)
str(test[,1:10])
?svm
test = na.omit(test)
fctr <- which(sapply(test, is.factor))
ind2 <- if (length(ind1) > 0L) fctr[-ind1] else fctr
# =============================================================================================================
# SVM
# =============================================================================================================
str(trainSet[,1:5])
ind1 <- which(trainSet %in% c("logical", "int"))
var_mode = sapply(trainSet, mode)
ind1 <- which(var_mode %in% c("logical", "int"))
test = toFactor(trainSet, c(2:785))
str(test[,1:10])
test = na.omit(test)
model.svm = svm(label ~. , data = test)
testfactor = test[ , sapply(test, nlevels) > 1]
str(testfactor)
model.svm = svm(label ~. , data = testfactor)
# =============================================================================================================
# converts cols in a dataset to numeric
#
toInteger = function(dataset, columns) {
for (i in 1:length(columns)) {
dataset[,columns[i]] = as.integer(dataset[,columns[i]])
}
return(dataset)
}
testInt = toInteger(testfactor,c(2:608))
model.svm = svm(label ~. , data = testInt)
model.svm = svm(label ~. , data = trainSet)
str(trainSet)
model.svm = svm(label ~. , data = trainSet)
str(trainSet[,35:41])
str(test[,35:41])
View(model.svm)
factorTrain = toFactor(trainSet, c(2:785))
factorTrain.v2 = factorTrain[ , sapply(factorTrain, nlevels) > 1]
svn.trainSet = toInteger(factorTrain.v2,c(2:608))
model.svm = svm(label ~. , data = factorTrain.v2)
model.svm.v1 = svm(label ~. , data = factorTrain.v2)
model.svm.v2 = svm(label ~. , data = svn.trainSet)
factorTest = toFactor(testSet, c(2:785))
factorTest.v2 = factorTest[ , sapply(factorTest, nlevels) > 1]
svn.testSet = toInteger(factorTrain.v2, c(2:608))
pred.svm.v1 = predict(model.svm.v1, factorTest.v2, type = 'class')
pred.svm.v2 = predict(model.svm.v2, svn.testSet, type = 'class')
svn.testSet = toInteger(factorTest.v2, c(2:608))
model.rf = randomForest(label~. data=trainSet)
model.rf = randomForest(label~., data=trainSet)
pred.rf = predict(model.rf, testSet, type = 'class')
rf.matrix = table(pred.rf, testSet$label)
(rf.matrix.stats = confusionMatrix(rf.matrix))
summary(model.rf)
model.rf
(rf.matrix.stats = confusionMatrix(rf.matrix))
model.rf = randomForest(label~., data=trainSet, ntree = 10)
model.rf
pred.rf = predict(model.rf, testSet, type = 'class')
rf.matrix = table(pred.rf, testSet$label)
(rf.matrix.stats = confusionMatrix(rf.matrix))
model.rf = randomForest(label~., data=trainSet, ntree = 100)
model.rf
model.rf = randomForest(label~., data=trainSet, ntree = 200)
model.rf
summary(model.rf)
pred.rf = predict(model.rf, testSet, type = 'class')
rf.matrix = table(pred.rf, testSet$label)
(rf.matrix.stats = confusionMatrix(rf.matrix))
model.rf = randomForest(label~., data=trainSet, ntree = 200)
model.rf
summary(model.rf)
pred.rf = predict(model.rf, testSet, type = 'class')
rf.matrix = table(pred.rf, testSet$label)
(rf.matrix.stats = confusionMatrix(rf.matrix))
model.rf.og = randomForest(label~., data=trainSet)
pred.rf = predict(model.rf.og, testSet, type = 'class')
model.rf.og = randomForest(label~., data=trainSet)
pred.rf.og = predict(model.rf.og, testSet, type = 'class')
rf.matrix.og = table(pred.rf.og, testSet$label)
(rf.matrix.stats.og = confusionMatrix(rf.matrix.og))
model.rf = randomForest(label~., data=trainSet, ntree = 200)
model.rf
summary(model.rf)
pred.rf = predict(model.rf, testSet, type = 'class')
rf.matrix = table(pred.rf, testSet$label)
(rf.matrix.stats = confusionMatrix(rf.matrix))
model.rf = randomForest(label~., data=trainSet, ntree = 300)
model.rf
summary(model.rf)
pred.rf = predict(model.rf, testSet, type = 'class')
rf.matrix = table(pred.rf, testSet$label)
(rf.matrix.stats = confusionMatrix(rf.matrix))
model.rf
(rf.matrix.stats = confusionMatrix(rf.matrix))
model.rf = randomForest(label~., data=trainSet, ntree = 400)
model.rf
summary(model.rf)
pred.rf = predict(model.rf, testSet, type = 'class')
rf.matrix = table(pred.rf, testSet$label)
(rf.matrix.stats = confusionMatrix(rf.matrix))
model.rf
(rf.matrix.stats = confusionMatrix(rf.matrix))
loadLibraries()
model.svn.og = svm(label ~., data = trainSet)
model.svn.og = svm(label ~., data = trainSet[,1:100])
model.svn.og = svm(label ~., data = trainSet[,1:100], scale = FALSE)
model.svn.og = svm(label ~., data = trainSet, scale = FALSE)
pred.svm = predict(model.svm, testSet, type = 'class')
model.svn = svm(label ~., data = trainSet, scale = FALSE)
pred.svm = predict(model.svm, testSet, type = 'class')
pred.svm = predict(model.svm, testSet)
model.svm = svm(label ~., data = trainSet, scale = FALSE)
pred.svm = predict(model.svm, testSet, type = 'class')
svm.matrix = table(pred.svm, testSet$label)
(svm.matrix.stats = confusionMatrix(svm.matrix))
(svm.matrix.stats = confusionMatrix(svm.matrix))
model.svm = svm(label ~., data = trainSet, scale = FALSE, cost = .1)
pred.svm = predict(model.svm, testSet, type = 'class')
svm.matrix = table(pred.svm, testSet$label)
(svm.matrix.stats = confusionMatrix(svm.matrix))
model.svm = svm(label ~., data = trainSet, scale = FALSE, cost = .1, kernel = 'polynomial')
pred.svm = predict(model.svm, testSet, type = 'class')
svm.matrix = table(pred.svm, testSet$label)
(svm.matrix.stats = confusionMatrix(svm.matrix))
model.svm = svm(label ~., data = trainSet, scale = FALSE)
pred.svm = predict(model.svm, testSet, type = 'class')
svm.matrix = table(pred.svm, testSet$label)
(svm.matrix.stats = confusionMatrix(svm.matrix))
model.svm.v1 = svm(label ~., data = trainSet, scale = FALSE, cost = .1, kernel = 'polynomial')
pred.svm.v1 = predict(model.svm.v1, testSet, type = 'class')
svm.matrix.v1 = table(pred.svm.v1, testSet$label)
(svm.matrix.stats = confusionMatrix(svm.matrix.v1))
model.svm.v1 = svm(label ~., data = trainSet, scale = FALSE, cost = .2, kernel = 'polynomial')
pred.svm.v1 = predict(model.svm.v1, testSet, type = 'class')
svm.matrix.v1 = table(pred.svm.v1, testSet$label)
(svm.matrix.stats = confusionMatrix(svm.matrix.v1))
model.svm.v1 = svm(label ~., data = trainSet, scale = FALSE, cost = .5, kernel = 'polynomial')
pred.svm.v1 = predict(model.svm.v1, testSet, type = 'class')
svm.matrix.v1 = table(pred.svm.v1, testSet$label)
(svm.matrix.stats = confusionMatrix(svm.matrix.v1))
?svm
model.svm.v1 = svm(label ~., data = trainSet, scale = FALSE, cost = .5, kernel = 'linear')
pred.svm.v1 = predict(model.svm.v1, testSet, type = 'class')
svm.matrix.v1 = table(pred.svm.v1, testSet$label)
(svm.matrix.stats = confusionMatrix(svm.matrix.v1))
model.svm.v1 = svm(label ~., data = trainSet, scale = FALSE, cost = .5, kernel = 'radial basis')
model.svm.v1 = svm(label ~., data = trainSet, scale = FALSE, cost = .5, kernel = 'sigmoid')
pred.svm.v1 = predict(model.svm.v1, testSet, type = 'class')
svm.matrix.v1 = table(pred.svm.v1, testSet$label)
(svm.matrix.stats = confusionMatrix(svm.matrix.v1))
model.svm.v1 = svm(label ~., data = trainSet, scale = FALSE, cost = .5, kernel = 'polynomial')
pred.svm.v1 = predict(model.svm.v1, testSet, type = 'class')
svm.matrix.v1 = table(pred.svm.v1, testSet$label)
(svm.matrix.stats = confusionMatrix(svm.matrix.v1))
model.svm.v1 = svm(label ~., data = trainSet, scale = FALSE, cost = .5, kernel = 'linear')
model.svm.v1
model.svm.v1 = svm(label ~., data = trainSet, scale = FALSE, cost = .5, kernel = 'polynomial')
model.svm.v1
pred.svm.v1 = predict(model.svm.v1, testSet, type = 'class')
svm.matrix.v1 = table(pred.svm.v1, testSet$label)
(svm.matrix.stats = confusionMatrix(svm.matrix.v1))
?knn
library(ElemStatLearn)
list.of.packages <- c("ggplot2", "Rcpp", "factoextra", "gridExtra", "grid", "cluster", "pvclust", "reshape2", "plyr", "scales",
"fpc", "HSAUR", "ClustMMDD", "tm", "stringr", "wordcloud", "slam", "quanteda", "SnowballC", "arules", "proxy", "cluster",
"stringi", "proxy", "Matrix", "tidytext", "plyr", "mclust", "gofastr", "RColorBrewer", "e1071", "openxlsx", "ISLR",
"MASS", "randomForest", "caret", "rpart", "rattle", "rpart.plot", "Cairo", "class", "tidyr", "reshape", "datasets", "arulesViz",
"arules", "lattice", "ElemStatLearn")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
for (i in 1:length(list.of.packages)) {
library(list.of.packages[i], character.only = T)
}
# stolen from site to create viz
#https://stats.stackexchange.com/questions/21572/how-to-plot-decision-boundary-of-a-k-nearest-neighbor-classifier-from-elements-o
mod15 <- knn(trainSet, testSet, k=5, prob=TRUE)
# stolen from site to create viz
#https://stats.stackexchange.com/questions/21572/how-to-plot-decision-boundary-of-a-k-nearest-neighbor-classifier-from-elements-o
mod15 <- knn(train = trainSet, test = testSet, cl = train_label, k=5, prob=TRUE)
prob <- attr(mod15, "prob")
prob <- ifelse(mod15=="1", prob, 1-prob)
px1 <- mixture.example$px1
px2 <- mixture.example$px2
prob15 <- matrix(prob, length(px1), length(px2))
par(mar=rep(2,4))
contour(px1, px2, prob15, levels=0.5, labels="", xlab="", ylab="", main=
"15-nearest neighbour", axes=FALSE)
points(x, col=ifelse(g==1, "coral", "cornflowerblue"))
contour(px1, px2, prob15, levels=0.5, labels="", xlab="", ylab="", main=
"5-nearest neighbour", axes=FALSE)
points(testSet$label, col=ifelse(g==1, "coral", "cornflowerblue"))
points(testSet$label, col=ifelse(train_label==1, "coral", "cornflowerblue"))
gd <- expand.grid(x=px1, y=px2)
points(gd, pch=".", cex=1.2, col=ifelse(prob15>0.5, "coral", "cornflowerblue"))
box()
plot(model.svm.v1, trainSet)
el071::plot(model.svm.v1, trainSet)
e1071::plot(model.svm.v1, trainSet)
install.packages("e1071")
model.svm.v1 = svm(label ~., data = trainSet, scale = FALSE, cost = .5, kernel = 'polynomial')
library("e1071", lib.loc="~/R/win-library/3.3")
model.svm.v1 = svm(label ~., data = trainSet, scale = FALSE, cost = .5, kernel = 'polynomial')
plot(model.svm.v1, trainSet)
plot(label ~., model.svm.v1, trainSet)
install.packages("kernlab")
model.test.svm = ksvm(label ~., data = trainSet, scale = FALSE, cost = .5, kernel = 'polynomial')
library(kernlab)
model.test.svm = ksvm(label ~., data = trainSet, scale = FALSE, cost = .5, kernel = 'polynomial')
model.test.svm = ksvm(label ~., data = trainSet)
?ksvm
model.test.svm = ksvm(label ~., data = trainSet, scaled = FALSE, kernel = 'polydot')
plot(model.test.svm, data=trainSet)
model.svm.v1
# =============================================================================================================
# load libraries
#
loadLibraries = function() {
list.of.packages <- c("ggplot2", "Rcpp", "factoextra", "gridExtra", "grid", "cluster", "pvclust", "reshape2", "plyr", "scales",
"fpc", "HSAUR", "ClustMMDD", "tm", "stringr", "wordcloud", "slam", "quanteda", "SnowballC", "arules", "proxy", "cluster",
"stringi", "proxy", "Matrix", "tidytext", "plyr", "mclust", "gofastr", "RColorBrewer", "e1071", "openxlsx", "ISLR",
"MASS", "randomForest", "caret", "rpart", "rattle", "rpart.plot", "Cairo", "class", "tidyr", "reshape", "datasets", "arulesViz",
"arules", "lattice", "ElemStatLearn")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
for (i in 1:length(list.of.packages)) {
library(list.of.packages[i], character.only = T)
}
# ONCE: install.packages("Snowball")
## NOTE Snowball is not yet available for R v 3.5.x
## So I cannot use it  - yet...
##library("Snowball")
}
loadLibraries()
grid.table(knn.matrix)
dev.off(dev.list()["RStudioGD"]) # clear plots
grid.table(knn.matrix)
grid.table(svm.matrix)
dev.off(dev.list()["RStudioGD"]) # clear plots
grid.table(svm.matrix.v1)
dev.off(dev.list()["RStudioGD"]) # clear plots
grid.table(knn.matrix)
dev.off(dev.list()["RStudioGD"]) # clear plots
grid.table(svm.matrix.v1)
dev.off(dev.list()["RStudioGD"]) # clear plots
grid.table(rf.matrix)
